{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/storage/ducpm/lung-segmentation\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score\n",
    "from src.metrics import *\n",
    "from src.data.data_modules import Covid19DataModule, PlethoraDataModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(tensor):\n",
    "    \"\"\"Flattens a given tensor such that the channel axis is first.\n",
    "    The shapes are transformed as follows:\n",
    "       (N, C, D, H, W) -> (C, N * D * H * W)\n",
    "    \"\"\"\n",
    "    # number of channels\n",
    "    C = tensor.size(1)\n",
    "    # new axis order\n",
    "    axis_order = (1, 0) + tuple(range(2, tensor.dim()))\n",
    "    # Transpose: (N, C, D, H, W) -> (C, N, D, H, W)\n",
    "    transposed = tensor.permute(axis_order)\n",
    "    # Flatten: (C, N, D, H, W) -> (C, N * D * H * W)\n",
    "    return transposed.contiguous().view(C, -1)\n",
    "\n",
    "def compute_per_channel_dice(input, target, epsilon=1e-6, weights=None):\n",
    "    \"\"\"\n",
    "    Implemented by https://github.com/wolny/pytorch-3dunet\n",
    "    \n",
    "    Computes DiceCoefficient as defined in V-net paperL https://arxiv.org/abs/1606.04797,\n",
    "    given a multi channel input and target.\n",
    "    Assumes the input is a normalized probability, e.g. a result of Sigmoid or Softmax function.\n",
    "    \n",
    "    Args:\n",
    "         input (torch.Tensor): NxCxSpatial input tensor\n",
    "         target (torch.Tensor): NxCxSpatial target tensor\n",
    "         epsilon (float): prevents division by zero\n",
    "         weight (torch.Tensor): Cx1 tensor of weight per channel/class\n",
    "    \"\"\"\n",
    "    assert input.shape == target.shape\n",
    "    \n",
    "    input = flatten(input).float()\n",
    "    target = flatten(target).float()\n",
    "    \n",
    "    inter = (input * target).sum(-1)\n",
    "    if weights is not None:\n",
    "        inter *= weights\n",
    "    \n",
    "    # extension proposed in V-net paper \n",
    "    denom = (input * input).sum(-1) + (target * target).sum(-1)\n",
    "    return 2 * (inter / denom.clamp(min=epsilon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. test samples: 5199\n"
     ]
    }
   ],
   "source": [
    "data_module_args = { \n",
    "   \"batch_size\": 8,\n",
    "   \"img_size\": 512,\n",
    "   \"clip_low\": -1000,\n",
    "   \"clip_high\": 1000,\n",
    "   \"pin_memory\": True,\n",
    "   \"num_workers\": 2\n",
    "}                                                              \n",
    "#dm = Covid19DataModule(**data_module_args)        \n",
    "dm = PlethoraDataModule(**data_module_args)\n",
    "dm.setup()\n",
    "print(\"No. test samples:\", len(dm.test_ds))\n",
    "test_loader = dm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "from src.models.unet import UNet\n",
    "net = UNet.load_from_checkpoint(\"logs/unet-plethora-512/version_0/ckpts/epoch=8-dice_coeff_val=0.942.ckpt\")\n",
    "net.to(device).eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-78b4c57511cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# batch['mask'] = batch['mask'][:4]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'img'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpred_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch' is not defined"
     ]
    }
   ],
   "source": [
    "# sanity check model predictions\n",
    "it = iter(test_loader)\n",
    "#for _ in range(8):\n",
    "#    batch = next(it)\n",
    "# batch['img'] = batch['img'][:4]\n",
    "# batch['mask'] = batch['mask'][:4]\n",
    "with torch.no_grad():\n",
    "    logits = net(batch['img'].to(device))\n",
    "    pred_masks = torch.argmax(logits, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_true_vs_pred(batch['img'], \n",
    "#                   batch['mask'], \n",
    "#                   pred_masks.cpu(), mask_alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dsc=0.964: 100%|██████████| 650/650 [20:13<00:00,  1.87s/it]          \n"
     ]
    }
   ],
   "source": [
    "dice_scores = []\n",
    "#pbar = tqdm(dm.test_dataloader())\n",
    "pbar = tqdm(test_loader)\n",
    "true_buffer = []\n",
    "pred_buffer = []\n",
    "# evaluate on test set\n",
    "for i, batch in enumerate(pbar):\n",
    "    X, y = batch[\"img\"].to(device), batch[\"mask\"].to(device)\n",
    "    slice_idxs = batch[\"slice_idx\"]\n",
    "    with torch.no_grad():\n",
    "        logits = net(X.to(device))\n",
    "        pred_masks = torch.argmax(logits, dim=1)\n",
    "    pred_masks = pred_masks.detach()\n",
    "    \n",
    "    split_idx = torch.where(slice_idxs == 0)[0]\n",
    "    if len(split_idx) > 1:\n",
    "        raise RuntimeError(f\"there are multiple zeros in slice_idxs: {slice_idxs}\")\n",
    "    split_idx = split_idx.item() if len(split_idx) > 0 \\\n",
    "            else None\n",
    "    true_buffer.append(y[:split_idx])\n",
    "    pred_buffer.append(pred_masks[:split_idx])\n",
    "    \n",
    "    # check if we have started to process a new CT scan\n",
    "    if (split_idx is not None and i > 0) or i == len(test_loader) - 1: \n",
    "        pbar.set_description(f\"calculating 3D dice\")\n",
    "        true_v_mask = torch.cat(true_buffer).reshape(1, -1)\n",
    "        pred_v_mask = torch.cat(pred_buffer).reshape(1, -1)\n",
    "    \n",
    "        dsc_v = dice_coeff_vectorized(pred_v_mask, true_v_mask, reduce_fn=None).item()\n",
    "        dice_scores.append(dsc_v)\n",
    "        pbar.set_description(f\"dsc={dsc_v:.3f}\")\n",
    "        # empty the buffers and collect slices from new CT scan\n",
    "        true_buffer = [y[split_idx:]]\n",
    "        pred_buffer = [pred_masks[split_idx:]]\n",
    "        \n",
    "        del true_v_mask\n",
    "        del pred_v_mask\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.970837050821723, 41)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(dice_scores), len(dice_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:lung-segmentation]",
   "language": "python",
   "name": "conda-env-lung-segmentation-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
